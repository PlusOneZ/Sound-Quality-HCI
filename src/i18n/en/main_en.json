{
  "title": "Sound Quality",
  "another_lang": "中",
  "menu": {
    "algo": "Algorithms",
    "quality": "Quality",
    "record": "Record",
    "augment": "Audio Denoise",
    "upload": "Upload File"
  },
  "actions": {
    "add": "Add",
    "edit": "Edit",
    "delete": "Delete",
    "save": "Save",
    "cancel": "Cancel",
    "search": "Search",
    "reset": "Reset",
    "back": "Back",
    "next": "Next",
    "previous": "Previous",
    "confirm": "Confirm",
    "close": "Close",
    "ok": "OK",
    "yes": "Yes",
    "no": "No",
    "submit": "Submit",
    "send": "Send",
    "download": "Download",
    "upload": "Upload",
    "send_email": "Send Email",
    "search_hint": "Search..."
  },
  "descriptions": {
    "all": "All",
    "algo": ""
  },
  "hints": {
    "analysisButton": "Upload for Analysis",
    "saveRecording": "Save current recording.",
    "cancelRecording": "Cancel recording (discard).",
    "clickToStartRecording": "Click button to start recoding.",
    "chooseFromLocal": "Choose From Local File",
    "currentAudioName": "Current Audio File: ",
    "chooseAlgorithms": "Choose Analysis Algorithms: ",
    "qualityResultTitle": "Result of Quality Assessment",
    "qualityResultOfAlgo": "Result of ",
    "overallScoreOfAlgo": "Overall Score",
    "timeConsumptionTitle": "Time Consumption of Each Algorithm"
  },
  "algo_brief_info": {
    "mosnet": "Use neural network to predict MOS score.",
    "srmr": "some scratch info about srmr",
    "bsseval": "some scratch info about bsseval",
    "pesq": "some scratch info about pesq",
    "sisdr": "some scratch info about sisdr",
    "stoi": "some scratch info about stoi"
  },
  "algo_md_info": {
    "mosnet": "The general idea of MOSNet is rather simple, which is to complete the modeling process of the human subjective congnition on the MOS score, and use neural network to predict the score. For the neural network, sufficient data is essential for avoiding overfitting. The architecture of MOSNet is LSTM, CNN and their combination. The output of MOSNet contains two MOS score, featuring the frame-level score and the utterance-level score.\n\n\n\n![e628cf719ba14da68e53ae02e87ffc1b](https://uniplus.oss-cn-shanghai.aliyuncs.com/uniplus/e628cf719ba14da68e53ae02e87ffc1b.png)\n\nThe loss function of MOSNet is a weighted average of the MSE of utterance-level score and the MSE of frame-level score.\n$$\nO=\\frac{1}{S} \\sum_{s=1}^{S}\\left[\\left(\\hat{Q}_{s}-Q_{s}\\right)^{2}+\\frac{\\alpha}{T_{s}} \\sum_{t=1}^{T_{s}}\\left(\\hat{Q}_{s}-q_{s, t}\\right)^{2}\\right]\n$$\n\n经过训练，MOSNet在VCC 2018数据集训练的结果在VCC 2016数据集上的泛化能力比较强\n\nThrough the training process, The MOSNet trained with VCC 2018 dataset has strong generalization ability on the VCC 2016 dataset.",
    "srmr": "The speech-to-reverberation modulation energy ratio (SRMR) is a non-intrusive metric for speech quality and intelligibility based on a modulation spectral representation of the speech signal. The metric was proposed by Falk et al. and recently updated for variability reduction and improved intelligibility estimation both for normal hearing listeners and cochlear implant users\n\n![Snipaste_2022-06-15_21-17-34](https://uniplus.oss-cn-shanghai.aliyuncs.com/uniplus/Snipaste_2022-06-15_21-17-34.png)\n\nIn order to reduce this difference,The SRMR thresholding will be calculated. The objective is to truncate extremely low energies, which lead to high ratios due to the division done in SRMR, and also limit the modulation energy dynamic range. In our modulation energy limitation scheme, we first compute the energy values for each of the acoustic and modulation frequencies in all frames, and then compute the average peak value.\n$$\n\\bar{E}_{p e a k}=\\max _{j, f_{b}}\\left(\\frac{1}{M} \\sum_{m=1}^{M} E_{j}\\left(m, f_{b}\\right)\\right)\n$$\n\nThe average peak will be use as an upper threshold of the modulation energy in each band for all frames. Finally an lower bound will be manually set to truncate the extremely low energies.\n\n\n",
    "bsseval": "BSS Eval is a Matlab toolbox to measure the performance of (blind) source separation algorithms within an evaluation framework where the original source signals are available as ground truth [1,3. The measures are based on the decomposition of each estimated source signal into a number of contributions corresponding to the target source, interference from unwanted sources, and artifacts such as \"musical noise\". They are valid for any type of data (audio, biomedical, etc), any mixture (instantaneous, convolutive, etc) and any algorithm (beamforming, ICA, time-frequency masking, etc). By separating the audio we get: \n\n\n\n$$\n\\widehat{s}_{j}=s_{\\text {target }}+e_{\\text {interf }}+e_{\\text {noise }}+e_{\\text {artif }}\n$$\nThe seperation result contains target, interference, noise and artifacts. For a good seperation audio, the first 3 metric values should be 0. The alogritm of the individual algorithm is:\n\n\n\n$$\n\\\n\\begin{aligned}\ns_{\\text {target }} &:=P_{s_{j}} \\widehat{s}_{j} \\\\\ne_{\\text {interf }} &:=P_{\\mathbf{s}} \\widehat{s}_{j}-P_{s_{j}} \\widehat{s}_{j} \\\\\ne_{\\text {noise }} &:=P_{\\mathbf{s}, \\mathbf{n}} \\widehat{s}_{j}-P_{\\mathbf{s}} \\widehat{s}_{j} \\\\\ne_{\\text {artif }} &:=\\widehat{s}_{j}-P_{\\mathbf{s}, \\mathbf{n}} \\widehat{s}_{j}\n\\end{aligned}\n$$\n\n\n\nwhich can be simply represented with vector diagram:\n\n![4](https://uniplus.oss-cn-shanghai.aliyuncs.com/uniplus/4.png)",
    "pesq": "| Audio Level |                 Evaluation Standand                  | Corresponding MOS |\n| ----------- | :--------------------------------------------------: | ----------------: |\n| A           |   clear and sound; low delay, fluent communication   |           4.0-5.0 |\n| B           |  clear; low delay but with mild blocking and noise   |           3.5-4.0 |\n| C           | Slightly unclear；Have delay but okay to communicate |           3.0-3.5 |\n| D           |    Unclear；Severe delay and requires repetition     |           1.5-3.0 |\n| E           |      Unrecognizable；Severe delay with blocking      |             0-1.5 |\n\nPESQ, as described in the standard, can carry out end-to-end audio quality testing, the reference signal (Reference speech) line in passed into the transmitter (the following figure is a telephone), after the telephone network to the receiving end, and then Line out passed out and directly back to the loop (Figure called the reference path Reference path) of the reference signal passed into the PESQ The algorithm proceeds, with reference evaluation, and finally generates the PESQ score.\n\nA simple PESQ algorithm is as follow：\n\n![v2-a133189ac2149596495439e1a4a2bc8c_1440w](https://uniplus.oss-cn-shanghai.aliyuncs.com/uniplus/v2-a133189ac2149596495439e1a4a2bc8c_1440w.jpg)\n\nIn brief, the time Alignment detects the input active speech segment, then performs the delay calculation and speech segmentation, and this algorithm is compatible with variable delays. Then the PESQ Algorithm calculates the aligned reference signal and the signal to be measured, gets their signals in the frequency domain with some compensation, and then transfers them to the loudness domain to compare the perceptual differences between the two signals according to the psychoacoustic model. Finally, the difference is mapped to a PESQ score similar to the MOS score, which ranges from -0.5 to 4.5.\n\n",
    "sisdr": "# 测试一级标题\n## 测试二级标题\n\n测试文本内容\n\n测试列表:\n\n* 列表项1\n* 列表项2\n\n测试表格\n\n| never    | Gonna |\n| -------- | ----- |\n| give you | up    |\n\n测试公式: $\\frac{1+2}{3\\times 4}$\n $$\\frac{1+2}{3 \\times 4}$$\n\n\n测试图片\n\n[![stoi.jpg](https://i.postimg.cc/JhL8ZV3x/stoi.jpg)](https://postimg.cc/yDv2CGb3)",
    "stoi": "# 测试一级标题\n## 测试二级标题\n\n测试文本内容\n\n测试列表:\n\n* 列表项1\n* 列表项2\n\n测试表格\n\n| never    | Gonna |\n| -------- | ----- |\n| give you | up    |\n\n测试公式: $\\frac{1+2}{3\\times 4}$\n $$\\frac{1+2}{3 \\times 4}$$\n\n\n测试图片\n\n[![stoi.jpg](https://i.postimg.cc/JhL8ZV3x/stoi.jpg)](https://postimg.cc/yDv2CGb3)"
  },
  "scoreDescription": {
    "five-metric": "Result is measured in five-point scale: ",
    "excellent-5": "优：4.0~5.0；评价：很好，听得清楚；延迟小，交流流畅",
    "good-5": "良：3.5~4.0；评价：稍差，听得清楚；延迟小，交流欠流畅，有点杂音",
    "medium-5": "中：3.0~3.5；评价：还可以，听不太清；有一定延迟，可以交流",
    "bad-5": "差：1.5~3.0；评价：勉强，听不太清；延迟较大，交流需要重复多遍",
    "worse-5": "劣：0~1.5；评价：极差，听不懂；延迟大，交流不通畅",
    "db": "The result is expressed in dB, higher is better.",
    "dimensionless": "The result dimensionless correlation coefficient, higher is better. 0=very bad, 1=very good."
  }
}
