{
  "title": "Sound Quality",
  "another_lang": "中",
  "menu": {
    "algo": "Algorithms",
    "quality": "Quality",
    "record": "Record",
    "augment": "Audio Denoise",
    "upload": "Upload File"
  },
  "actions": {
    "add": "Add",
    "edit": "Edit",
    "delete": "Delete",
    "save": "Save",
    "cancel": "Cancel",
    "search": "Search",
    "reset": "Reset",
    "back": "Back",
    "next": "Next",
    "previous": "Previous",
    "confirm": "Confirm",
    "close": "Close",
    "ok": "OK",
    "yes": "Yes",
    "no": "No",
    "submit": "Submit",
    "send": "Send",
    "download": "Download",
    "upload": "Upload",
    "send_email": "Send Email",
    "search_hint": "Search..."
  },
  "descriptions": {
    "all": "All",
    "algo": ""
  },
  "hints": {
    "analysisButton": "Upload for Analysis",
    "saveRecording": "Save current recording.",
    "cancelRecording": "Cancel recording (discard).",
    "clickToStartRecording": "Click button to start recoding.",
    "chooseFromLocal": "Choose From Local File",
    "currentAudioName": "Current Audio File: ",
    "chooseAlgorithms": "Choose Analysis Algorithms: ",
    "qualityResultTitle": "Result of Quality Assessment",
    "qualityResultOfAlgo": "Result of ",
    "overallScoreOfAlgo": "Overall Score",
    "timeConsumptionTitle": "Time Consumption of Each Algorithm",
    "qualityTitle": "Sound Quality Analysis",
    "denoiseTitle": "Audio Denoising",
    "denoiseButton": "Upload for Denoising"
  },
  "algo_brief_info": {
    "mosnet": "Use neural network to predict MOS.",
    "srmr": "Speech-reverberation modulation ratio",
    "bsseval": "Measure source separation algorithms",
    "pesq": "Perceptual eval of speech quality",
    "sisdr": "Scale-Invariant SDR",
    "stoi": "Short-Time Objective Intelligibility"
  },
  "algo_md_info": {
    "mosnet": "The general idea of MOSNet is rather simple, which is to complete the modeling process of the human subjective congnition on the MOS score, and use neural network to predict the score. For the neural network, sufficient data is essential for avoiding overfitting. The architecture of MOSNet is LSTM, CNN and their combination. The output of MOSNet contains two MOS score, featuring the frame-level score and the utterance-level score.\n\n\n\n![e628cf719ba14da68e53ae02e87ffc1b](https://uniplus.oss-cn-shanghai.aliyuncs.com/uniplus/e628cf719ba14da68e53ae02e87ffc1b.png)\n\nThe loss function of MOSNet is a weighted average of the MSE of utterance-level score and the MSE of frame-level score.\n$$\nO=\\frac{1}{S} \\sum_{s=1}^{S}\\left[\\left(\\hat{Q}_{s}-Q_{s}\\right)^{2}+\\frac{\\alpha}{T_{s}} \\sum_{t=1}^{T_{s}}\\left(\\hat{Q}_{s}-q_{s, t}\\right)^{2}\\right]\n$$\n\n经过训练，MOSNet在VCC 2018数据集训练的结果在VCC 2016数据集上的泛化能力比较强\n\nThrough the training process, The MOSNet trained with VCC 2018 dataset has strong generalization ability on the VCC 2016 dataset.",
    "srmr": "The speech-to-reverberation modulation energy ratio (SRMR) is a non-intrusive metric for speech quality and intelligibility based on a modulation spectral representation of the speech signal. The metric was proposed by Falk et al. and recently updated for variability reduction and improved intelligibility estimation both for normal hearing listeners and cochlear implant users\n\n![Snipaste_2022-06-15_21-17-34](https://uniplus.oss-cn-shanghai.aliyuncs.com/uniplus/Snipaste_2022-06-15_21-17-34.png)\n\nIn order to reduce this difference,The SRMR thresholding will be calculated. The objective is to truncate extremely low energies, which lead to high ratios due to the division done in SRMR, and also limit the modulation energy dynamic range. In our modulation energy limitation scheme, we first compute the energy values for each of the acoustic and modulation frequencies in all frames, and then compute the average peak value.\n$$\n\\bar{E}_{p e a k}=\\max _{j, f_{b}}\\left(\\frac{1}{M} \\sum_{m=1}^{M} E_{j}\\left(m, f_{b}\\right)\\right)\n$$\n\nThe average peak will be use as an upper threshold of the modulation energy in each band for all frames. Finally an lower bound will be manually set to truncate the extremely low energies.\n\n\n",
    "bsseval": "BSS Eval is a Matlab toolbox to measure the performance of (blind) source separation algorithms within an evaluation framework where the original source signals are available as ground truth [1,3. The measures are based on the decomposition of each estimated source signal into a number of contributions corresponding to the target source, interference from unwanted sources, and artifacts such as \"musical noise\". They are valid for any type of data (audio, biomedical, etc), any mixture (instantaneous, convolutive, etc) and any algorithm (beamforming, ICA, time-frequency masking, etc). By separating the audio we get: \n\n\n\n$$\n\\widehat{s}_{j}=s_{\\text {target }}+e_{\\text {interf }}+e_{\\text {noise }}+e_{\\text {artif }}\n$$\nThe seperation result contains target, interference, noise and artifacts. For a good seperation audio, the first 3 metric values should be 0. The alogritm of the individual algorithm is:\n\n\n\n$$\n\\\n\\begin{aligned}\ns_{\\text {target }} &:=P_{s_{j}} \\widehat{s}_{j} \\\\\ne_{\\text {interf }} &:=P_{\\mathbf{s}} \\widehat{s}_{j}-P_{s_{j}} \\widehat{s}_{j} \\\\\ne_{\\text {noise }} &:=P_{\\mathbf{s}, \\mathbf{n}} \\widehat{s}_{j}-P_{\\mathbf{s}} \\widehat{s}_{j} \\\\\ne_{\\text {artif }} &:=\\widehat{s}_{j}-P_{\\mathbf{s}, \\mathbf{n}} \\widehat{s}_{j}\n\\end{aligned}\n$$\n\n\n\nwhich can be simply represented with vector diagram:\n\n![4](https://uniplus.oss-cn-shanghai.aliyuncs.com/uniplus/4.png)",
    "pesq": "| Audio Level |                 Evaluation Standand                  | Corresponding MOS |\n| ----------- | :--------------------------------------------------: | ----------------: |\n| A           |   clear and sound; low delay, fluent communication   |           4.0-5.0 |\n| B           |  clear; low delay but with mild blocking and noise   |           3.5-4.0 |\n| C           | Slightly unclear；Have delay but okay to communicate |           3.0-3.5 |\n| D           |    Unclear；Severe delay and requires repetition     |           1.5-3.0 |\n| E           |      Unrecognizable；Severe delay with blocking      |             0-1.5 |\n\nPESQ, as described in the standard, can carry out end-to-end audio quality testing, the reference signal (Reference speech) line in passed into the transmitter (the following figure is a telephone), after the telephone network to the receiving end, and then Line out passed out and directly back to the loop (Figure called the reference path Reference path) of the reference signal passed into the PESQ The algorithm proceeds, with reference evaluation, and finally generates the PESQ score.\n\nA simple PESQ algorithm is as follow：\n\n![v2-a133189ac2149596495439e1a4a2bc8c_1440w](https://uniplus.oss-cn-shanghai.aliyuncs.com/uniplus/v2-a133189ac2149596495439e1a4a2bc8c_1440w.jpg)\n\nIn brief, the time Alignment detects the input active speech segment, then performs the delay calculation and speech segmentation, and this algorithm is compatible with variable delays. Then the PESQ Algorithm calculates the aligned reference signal and the signal to be measured, gets their signals in the frequency domain with some compensation, and then transfers them to the loudness domain to compare the perceptual differences between the two signals according to the psychoacoustic model. Finally, the difference is mapped to a PESQ score similar to the MOS score, which ranges from -0.5 to 4.5.\n\n",
    "sisdr": "\u200B\tSISDR is a scale-invariant SDR(SISDR) algorithm based on SDR(signal distortion ratio). The algorithm uses the following formula to calculate SNR. The relationship between SNR and SI-SDR is shown below.\n\n![Snipaste_2022-06-19_00-40-57](https://uniplus.oss-cn-shanghai.aliyuncs.com/uniplus/Snipaste_2022-06-19_00-40-57.png)\n\n\n\n\u200B\tTo ensure that the residual is indeed orthogonal to the target, we can either rescale the target or rescale the estimate. Rescaling the target such that the residual is orthogonal to it corresponds to fifinding the orthogonal projection of the estimate *s*ˆ on the line spanned by the target *s*, or equivalently fifinding the closest point to *s*ˆ along that line.This leads to two equivalent defifinitions for what we call the scale invariant signal-to-distortion ratio (SDR):\n\n![Snipaste_2022-06-19_00-41-18](https://uniplus.oss-cn-shanghai.aliyuncs.com/uniplus/Snipaste_2022-06-19_00-41-18.png)\n\n\n\n",
    "stoi": "\u200B\tThe algorithm presents an objective solvability measure, which shows the ability of highly correlated (RHO =0.95) and TF-weighted noise speech with solvability. The performance of this method is significantly better than the other three more complex objective measurement methods.\n\nTo compare the results between the objective measures and the subjective intelligibility scores directly, a mapping is needed in order to account for a nonlinear relation between the objective and subjective values. For the proposed method, and the CSTI a logistic function is applied：\n\n![Snipaste_2022-06-19_00-46-57](https://uniplus.oss-cn-shanghai.aliyuncs.com/uniplus/Snipaste_2022-06-19_00-46-57.png)\n\nwhile for DAU and NSEC a better fifit was observed with the following function：\n\n![Snipaste_2022-06-19_00-47-05](https://uniplus.oss-cn-shanghai.aliyuncs.com/uniplus/Snipaste_2022-06-19_00-47-05.png)\n\n\u200B\twhere *a*, *b* and *c* in (7) and (8) are free parameters, which are fifitted to the subjective data with a nonlinear least squares procedure, and *d* denotes the objective outcome. Due to better results with the latter proposed mapping for NSEC.The performance of all the objective measures is evaluated by means of the root of the mean squared prediction error (RMSE),\n\n![Snipaste_2022-06-19_00-47-12](https://uniplus.oss-cn-shanghai.aliyuncs.com/uniplus/Snipaste_2022-06-19_00-47-12.png)\n\n\u200B\twhere *s* refers to the subjective score, *S* denotes the total number of conditions in the subset, and *i* runs over all subset-conditions.In addition, the correlation coeffificient between the subjective and objective data is calculated.\n\n![Snipaste_2022-06-19_00-47-19](https://uniplus.oss-cn-shanghai.aliyuncs.com/uniplus/Snipaste_2022-06-19_00-47-19.png)"
  },
  "scoreDescription": {
    "five-metric": "Result is measured in five-point scale: ",
    "excellent-5": "A: 4.0-5.0; Clear and sound; low delay, fluent communication.",
    "good-5": "B：3.5~4.0；Clear; low delay but with mild blocking and noise.",
    "medium-5": "C：3.0~3.5；Slightly unclear；Have delay but okay to communicate.",
    "bad-5": "D：1.5~3.0；Unclear；Severe delay and requires repetition.",
    "worse-5": "E：0~1.5；Unrecognizable；Severe delay with blocking.",
    "db": "The result is expressed in dB, higher is better.",
    "dimensionless": "The result dimensionless correlation coefficient, higher is better. 0=very bad, 1=very good."
  }
}
